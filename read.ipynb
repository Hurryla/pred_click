{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "train_data_path = \"train.gz\"\n",
    "test_data_path = \"test.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train data sample using pd chunks. Each chunk has a size of 1000000\n",
    "train_data = pd.read_csv(train_data_path, chunksize = 1000000)\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "for chunk in train_data:\n",
    "    train_df = pd.concat([train_df, chunk.sample(frac=.05, replace=False, random_state=123)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data\n",
    "test_data = pd.read_csv(test_data_path, chunksize = 1000000)\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for chunk in test_data:\n",
    "    test_df = pd.concat([test_df, chunk], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.loc[0:2021448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373315</th>\n",
       "      <td>2.754752e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14102102</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>d9750ee7</td>\n",
       "      <td>98572c79</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17753</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1993</td>\n",
       "      <td>2</td>\n",
       "      <td>1063</td>\n",
       "      <td>-1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459286</th>\n",
       "      <td>9.630799e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102102</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15699</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100083</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262398</th>\n",
       "      <td>1.048226e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102102</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15703</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100083</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789396</th>\n",
       "      <td>1.830856e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102104</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>b8eae5f9</td>\n",
       "      <td>1e334bd3</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19950</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1800</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>100077</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383229</th>\n",
       "      <td>3.559389e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102102</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15701</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
       "373315  2.754752e+18      1  14102102  1005           1  d9750ee7    98572c79   \n",
       "459286  9.630799e+18      0  14102102  1005           0  1fbe01fe    f3845767   \n",
       "262398  1.048226e+19      0  14102102  1005           0  1fbe01fe    f3845767   \n",
       "789396  1.830856e+19      0  14102104  1005           1  b8eae5f9    1e334bd3   \n",
       "383229  3.559389e+18      0  14102102  1005           0  1fbe01fe    f3845767   \n",
       "\n",
       "       site_category    app_id app_domain  ... device_type device_conn_type  \\\n",
       "373315      f028772b  ecad2386   7801e8d9  ...           1                0   \n",
       "459286      28905ebd  ecad2386   7801e8d9  ...           1                0   \n",
       "262398      28905ebd  ecad2386   7801e8d9  ...           1                0   \n",
       "789396      f028772b  ecad2386   7801e8d9  ...           1                0   \n",
       "383229      28905ebd  ecad2386   7801e8d9  ...           1                0   \n",
       "\n",
       "          C14  C15  C16   C17  C18   C19     C20  C21  \n",
       "373315  17753  320   50  1993    2  1063      -1   33  \n",
       "459286  15699  320   50  1722    0    35  100083   79  \n",
       "262398  15703  320   50  1722    0    35  100083   79  \n",
       "789396  19950  320   50  1800    3   167  100077   23  \n",
       "383229  15701  320   50  1722    0    35      -1   79  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2021448 entries, 373315 to 40318589\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   id                float64\n",
      " 1   click             int64  \n",
      " 2   hour              int64  \n",
      " 3   C1                int64  \n",
      " 4   banner_pos        int64  \n",
      " 5   site_id           object \n",
      " 6   site_domain       object \n",
      " 7   site_category     object \n",
      " 8   app_id            object \n",
      " 9   app_domain        object \n",
      " 10  app_category      object \n",
      " 11  device_id         object \n",
      " 12  device_ip         object \n",
      " 13  device_model      object \n",
      " 14  device_type       int64  \n",
      " 15  device_conn_type  int64  \n",
      " 16  C14               int64  \n",
      " 17  C15               int64  \n",
      " 18  C16               int64  \n",
      " 19  C17               int64  \n",
      " 20  C18               int64  \n",
      " 21  C19               int64  \n",
      " 22  C20               int64  \n",
      " 23  C21               int64  \n",
      "dtypes: float64(1), int64(14), object(9)\n",
      "memory usage: 385.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#quick information on the data\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.156582e+19    1\n",
      "1.608933e+19    1\n",
      "1.050306e+19    1\n",
      "1.604667e+19    1\n",
      "5.166533e+18    1\n",
      "               ..\n",
      "5.820502e+18    1\n",
      "4.844970e+18    1\n",
      "3.788262e+18    1\n",
      "5.010368e+18    1\n",
      "1.072459e+19    1\n",
      "Name: id, Length: 2021448, dtype: int64\n",
      "0    1677654\n",
      "1     343794\n",
      "Name: click, dtype: int64\n",
      "14102209    22395\n",
      "14102210    21890\n",
      "14102813    21550\n",
      "14102212    20458\n",
      "14102814    19423\n",
      "            ...  \n",
      "14102419     1733\n",
      "14102423     1305\n",
      "14102420     1171\n",
      "14102421      992\n",
      "14102422      724\n",
      "Name: hour, Length: 240, dtype: int64\n",
      "1005    1857442\n",
      "1002     110650\n",
      "1010      45052\n",
      "1012       5780\n",
      "1007       1782\n",
      "1001        456\n",
      "1008        286\n",
      "Name: C1, dtype: int64\n",
      "0    1454765\n",
      "1     563132\n",
      "7       2150\n",
      "2        653\n",
      "4        350\n",
      "5        284\n",
      "3        114\n",
      "Name: banner_pos, dtype: int64\n",
      "85f751fd    728733\n",
      "1fbe01fe    324585\n",
      "e151e245    131951\n",
      "d9750ee7     48385\n",
      "5b08c53b     45472\n",
      "             ...  \n",
      "063584d1         1\n",
      "2a555dc4         1\n",
      "c685914b         1\n",
      "4edf288e         1\n",
      "23029590         1\n",
      "Name: site_id, Length: 3030, dtype: int64\n",
      "c4e18dd6    755387\n",
      "f3845767    324585\n",
      "7e091613    166487\n",
      "7687a86e     64180\n",
      "98572c79     50037\n",
      "             ...  \n",
      "b891312a         1\n",
      "16e653cc         1\n",
      "3edf52bf         1\n",
      "0c38ebbf         1\n",
      "20e81578         1\n",
      "Name: site_domain, Length: 3520, dtype: int64\n",
      "50e219e0    825363\n",
      "f028772b    634678\n",
      "28905ebd    368915\n",
      "3e814130    152146\n",
      "f66779e6     12691\n",
      "75fa27f6      7957\n",
      "335d28a8      6879\n",
      "76b2941d      5224\n",
      "c0dd3be3      2093\n",
      "72722551      1394\n",
      "dedf689d      1254\n",
      "70fb0e29      1211\n",
      "0569f928       832\n",
      "8fd0aea4       348\n",
      "a818d37a       173\n",
      "42a36e14       141\n",
      "e787de0e        58\n",
      "bcf865d9        49\n",
      "5378d028        24\n",
      "9ccfa2ea        15\n",
      "c706e647         1\n",
      "74073276         1\n",
      "da34532e         1\n",
      "Name: site_category, dtype: int64\n",
      "ecad2386    1292715\n",
      "92f5800b      77953\n",
      "e2fcccd2      55947\n",
      "febd1138      37694\n",
      "9c13b419      37688\n",
      "             ...   \n",
      "ccf86165          1\n",
      "c0994057          1\n",
      "f54e5e1e          1\n",
      "14d0305b          1\n",
      "a1b2b43a          1\n",
      "Name: app_id, Length: 3965, dtype: int64\n",
      "7801e8d9    1362909\n",
      "2347f47a     261428\n",
      "ae637522      94232\n",
      "5c5a694b      55953\n",
      "82e27996      37694\n",
      "             ...   \n",
      "94007c57          1\n",
      "e9d5949e          1\n",
      "435769ed          1\n",
      "55240cf0          1\n",
      "32f9558b          1\n",
      "Name: app_domain, Length: 253, dtype: int64\n",
      "07d7df22    1309446\n",
      "0f2161f8     477183\n",
      "cef3e649      86447\n",
      "8ded1f7a      73384\n",
      "f95efa07      56822\n",
      "d1327cf5       6192\n",
      "dc97ec06       2832\n",
      "09481d60       2755\n",
      "75d80bbe       2031\n",
      "fc6fa53d       1171\n",
      "4ce2e9fc        991\n",
      "879c24eb        644\n",
      "a3c42688        548\n",
      "4681bb9d        317\n",
      "0f9a328c        273\n",
      "a86a3e89        135\n",
      "2281a340        117\n",
      "8df2e842         69\n",
      "79f0b860         18\n",
      "0bfbc358         17\n",
      "2fc4f2aa         12\n",
      "a7fd01ec         12\n",
      "7113d72a         11\n",
      "5326cf99          8\n",
      "18b1e0be          6\n",
      "bf8ac856          3\n",
      "0d82db25          2\n",
      "4b7ade46          1\n",
      "bd41f328          1\n",
      "Name: app_category, dtype: int64\n",
      "a99f214a    1668710\n",
      "0f7c61dc       1049\n",
      "c357dbff        971\n",
      "936e92fb        723\n",
      "afeffc18        476\n",
      "             ...   \n",
      "5e7e2617          1\n",
      "1eb0284f          1\n",
      "c5274d17          1\n",
      "241c7632          1\n",
      "53a1c276          1\n",
      "Name: device_id, Length: 280212, dtype: int64\n",
      "6b9769f2    10319\n",
      "431b3174     6761\n",
      "009a7861     4443\n",
      "285aa37d     4396\n",
      "af9205f9     4369\n",
      "            ...  \n",
      "da239fcb        1\n",
      "9ad00007        1\n",
      "8488899d        1\n",
      "8a3f0180        1\n",
      "23d0dec5        1\n",
      "Name: device_ip, Length: 969833, dtype: int64\n",
      "8a4875bd    122642\n",
      "1f0bc64f     71419\n",
      "d787e91b     70441\n",
      "76dc4769     38324\n",
      "be6db1d7     37136\n",
      "             ...  \n",
      "6538d488         1\n",
      "d1782df5         1\n",
      "644160a2         1\n",
      "36cda1d1         1\n",
      "c9797678         1\n",
      "Name: device_model, Length: 5788, dtype: int64\n",
      "1    1865744\n",
      "0     110650\n",
      "4      38618\n",
      "5       6434\n",
      "2          2\n",
      "Name: device_type, dtype: int64\n",
      "0    1743896\n",
      "2     166082\n",
      "3     109312\n",
      "5       2158\n",
      "Name: device_conn_type, dtype: int64\n",
      "4687     47047\n",
      "21611    44732\n",
      "21189    38504\n",
      "21191    38196\n",
      "19772    36438\n",
      "         ...  \n",
      "23475        1\n",
      "12220        1\n",
      "22448        1\n",
      "23324        1\n",
      "23496        1\n",
      "Name: C14, Length: 2362, dtype: int64\n",
      "320     1885405\n",
      "300      116852\n",
      "216       14966\n",
      "728        3741\n",
      "120         172\n",
      "1024        130\n",
      "480         108\n",
      "768          74\n",
      "Name: C15, dtype: int64\n",
      "50      1907127\n",
      "250       90054\n",
      "36        14966\n",
      "480        5076\n",
      "90         3741\n",
      "20          172\n",
      "768         130\n",
      "320         108\n",
      "1024         74\n",
      "Name: C16, dtype: int64\n",
      "1722    226169\n",
      "2424     76700\n",
      "2227     73491\n",
      "1800     59464\n",
      "423      47047\n",
      "         ...  \n",
      "2722         2\n",
      "2521         1\n",
      "2448         1\n",
      "2585         1\n",
      "2346         1\n",
      "Name: C17, Length: 425, dtype: int64\n",
      "0    847898\n",
      "3    682959\n",
      "2    354690\n",
      "1    135901\n",
      "Name: C18, dtype: int64\n",
      "35      609538\n",
      "39      440967\n",
      "167     157038\n",
      "161      79712\n",
      "47       72731\n",
      "         ...  \n",
      "45         160\n",
      "683         40\n",
      "1447         9\n",
      "545          6\n",
      "1195         5\n",
      "Name: C19, Length: 66, dtype: int64\n",
      "-1         947495\n",
      " 100084    122041\n",
      " 100148     89506\n",
      " 100111     85217\n",
      " 100077     78544\n",
      "            ...  \n",
      " 100078         1\n",
      " 100157         1\n",
      " 100006         1\n",
      " 100008         1\n",
      " 100027         1\n",
      "Name: C20, Length: 166, dtype: int64\n",
      "23     444844\n",
      "221    252323\n",
      "79     231147\n",
      "48     108049\n",
      "71     105554\n",
      "61     101983\n",
      "157     93022\n",
      "32      88670\n",
      "33      74716\n",
      "52      59969\n",
      "42      51036\n",
      "51      42509\n",
      "15      38647\n",
      "212     32883\n",
      "43      29712\n",
      "117     21197\n",
      "229     20166\n",
      "13      19421\n",
      "16      17525\n",
      "156     16755\n",
      "68      16287\n",
      "159     14475\n",
      "95      14030\n",
      "46      11835\n",
      "246     10042\n",
      "69       8782\n",
      "91       8579\n",
      "17       8307\n",
      "76       7010\n",
      "111      6945\n",
      "70       6603\n",
      "90       6385\n",
      "110      6081\n",
      "171      5572\n",
      "204      4652\n",
      "101      4136\n",
      "253      3917\n",
      "112      3732\n",
      "82       3619\n",
      "100      3229\n",
      "178      2503\n",
      "182      2490\n",
      "108      2340\n",
      "35       2216\n",
      "94       1127\n",
      "251      1071\n",
      "116       819\n",
      "194       704\n",
      "20        696\n",
      "93        643\n",
      "102       446\n",
      "104       408\n",
      "126       386\n",
      "163       298\n",
      "177       284\n",
      "255       219\n",
      "195       175\n",
      "1         162\n",
      "219        97\n",
      "85         18\n",
      "Name: C21, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in train_df.columns:\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some feature engineering and pipeline building\n",
    "# get the day of the weeko through a pipeline class\n",
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    '''Custom transformer for making date variables'''\n",
    "    def __init__(self, data_col):\n",
    "        self.data_col = data_col\n",
    "        \n",
    "    def build_date(self, hour):\n",
    "        day = str(hour)[4:6]\n",
    "        month = str(hour)[2:4]\n",
    "        year = '20'+str(hour)[0:2]\n",
    "        return day + '-' + month + '-' + year\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_ = X.copy()\n",
    "        X_['fdate'] = pd.to_datetime(X_.hour.apply(self.build_date))\n",
    "        X_['weekday'] = X_['fdate'].dt.dayofweek.astype(str)\n",
    "        return X_\n",
    "\n",
    "# many of our categorical variables have high cardinality. let's try target encoding/mean encoding on them\n",
    "class EncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    '''Custom transformer for encoding categorical variables'''\n",
    "    def __init__(self, encoder, target, train):\n",
    "        self.encoder = encoder\n",
    "        self.target = target\n",
    "        self.train = train\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        if self.train == 1:\n",
    "            X_ = self.encoder.fit_transform(X_, self.target)\n",
    "        elif self.train == 0:\n",
    "            X_ = self.encoder.transform(X_, self.target)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['hour','C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
    "       'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n",
    "       'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n",
    "       'C17', 'C18', 'C19', 'C20', 'C21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "# declare target encoder\n",
    "encoder = TargetEncoder(cols = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
    "       'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n",
    "       'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n",
    "       'C17', 'C18', 'C19', 'C20', 'C21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training and test sets\n",
    "X_train = train_df.drop(['click', 'id'], axis=1)\n",
    "y_train = train_df.click.values\n",
    "X_test = test_df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
    "       'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip',\n",
    "       'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16',\n",
    "       'C17', 'C18', 'C19', 'C20', 'C21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline steps\n",
    "train = 1\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('date_maker', DateTransformer('hour')),\n",
    "    ('en_coder', EncoderTransformer(encoder, y_train, train))\n",
    "    #('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create second pipeline step. alternatively we could have combined the two pipelines using the Column Transformer module\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform our trainingv data on our pieplines\n",
    "X_train_tr = cat_pipeline.fit_transform(X_train)\n",
    "X_train_tr = num_pipeline.fit_transform(X_train_tr[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _logistic_regression_path\n",
      "    w0, n_iter_i = _newton_cg(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 181, in _newton_cg\n",
      "    fgrad, fhess_p = grad_hess(xk, *args)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py\", line 324, in gradient_hessian_product\n",
      "    hX = hessian[:, np.newaxis] * X\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 259. MiB for an array with shape (1617158, 21) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _logistic_regression_path\n",
      "    w0, n_iter_i = _newton_cg(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 181, in _newton_cg\n",
      "    fgrad, fhess_p = grad_hess(xk, *args)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py\", line 308, in gradient_hessian_product\n",
      "    gradient, hessian = self.base_loss.gradient_hessian(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\_loss\\loss.py\", line 360, in gradient_hessian\n",
      "    hessian_out = np.empty_like(raw_prediction)\n",
      "  File \"<__array_function__ internals>\", line 5, in empty_like\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.3 MiB for an array with shape (1617158,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _logistic_regression_path\n",
      "    w0, n_iter_i = _newton_cg(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 181, in _newton_cg\n",
      "    fgrad, fhess_p = grad_hess(xk, *args)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py\", line 324, in gradient_hessian_product\n",
      "    hX = hessian[:, np.newaxis] * X\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 259. MiB for an array with shape (1617159, 21) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _logistic_regression_path\n",
      "    w0, n_iter_i = _newton_cg(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 193, in _newton_cg\n",
      "    xsupi = _cg(fhess_p, fgrad, maxiter=maxinner, tol=termcond)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 88, in _cg\n",
      "    Ap = fhess_p(psupi)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py\", line 343, in hessp\n",
      "    ret[:n_features] = np.linalg.multi_dot([X.T, hX, s[:n_features]])\n",
      "  File \"<__array_function__ internals>\", line 5, in multi_dot\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py\", line 2727, in multi_dot\n",
      "    result = _multi_dot_three(arrays[0], arrays[1], arrays[2], out=out)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py\", line 2759, in _multi_dot_three\n",
      "    return dot(A, dot(B, C), out=out)\n",
      "  File \"<__array_function__ internals>\", line 5, in dot\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.3 MiB for an array with shape (1617159, 1) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _logistic_regression_path\n",
      "    w0, n_iter_i = _newton_cg(\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 193, in _newton_cg\n",
      "    xsupi = _cg(fhess_p, fgrad, maxiter=maxinner, tol=termcond)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 88, in _cg\n",
      "    Ap = fhess_p(psupi)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py\", line 343, in hessp\n",
      "    ret[:n_features] = np.linalg.multi_dot([X.T, hX, s[:n_features]])\n",
      "  File \"<__array_function__ internals>\", line 5, in multi_dot\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py\", line 2727, in multi_dot\n",
      "    result = _multi_dot_three(arrays[0], arrays[1], arrays[2], out=out)\n",
      "  File \"c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py\", line 2759, in _multi_dot_three\n",
      "    return dot(A, dot(B, C), out=out)\n",
      "  File \"<__array_function__ internals>\", line 5, in dot\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.3 MiB for an array with shape (1617158, 1) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\x2939\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# we want to use logistic regression because of the binary nature of our target. \n",
    "# but we have some class imbalance so let's first use a gird search to find the right weights for our model\n",
    "lr = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "#Setting the range for class weights\n",
    "weights = np.linspace(0.0,0.99,6)\n",
    "\n",
    "\n",
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= lr, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          verbose=2).fit(X_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 0.8, 1: 0.2}, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.8, 1: 0.2}, max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.8, 1: 0.2}, max_iter=5000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare sklearn logistic regressor and fit the model using the optimal classw weights from above\n",
    "lr = LogisticRegression(class_weight={0: 0.8, 1: 0.2}, max_iter=5000)\n",
    "lr.fit(X_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.360985\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:              2021448\n",
      "Model:                          Logit   Df Residuals:                  2021426\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Mon, 19 Sep 2022   Pseudo R-squ.:                  0.2084\n",
      "Time:                        12:59:50   Log-Likelihood:            -7.2971e+05\n",
      "converged:                       True   LL-Null:                   -9.2178e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.0094      0.003   -777.599      0.000      -2.014      -2.004\n",
      "x1             0.0330      0.012      2.644      0.008       0.009       0.058\n",
      "x2            -0.0347      0.003    -13.786      0.000      -0.040      -0.030\n",
      "x3             0.1488      0.006     26.356      0.000       0.138       0.160\n",
      "x4             0.3449      0.006     60.660      0.000       0.334       0.356\n",
      "x5            -0.0080      0.003     -2.493      0.013      -0.014      -0.002\n",
      "x6             0.4324      0.004    116.985      0.000       0.425       0.440\n",
      "x7            -0.1339      0.004    -32.998      0.000      -0.142      -0.126\n",
      "x8            -0.1488      0.004    -42.046      0.000      -0.156      -0.142\n",
      "x9             0.2596      0.003     96.497      0.000       0.254       0.265\n",
      "x10            0.7876      0.002    339.321      0.000       0.783       0.792\n",
      "x11            0.1297      0.003     46.618      0.000       0.124       0.135\n",
      "x12           -0.0638      0.012     -5.198      0.000      -0.088      -0.040\n",
      "x13            0.0059      0.004      1.622      0.105      -0.001       0.013\n",
      "x14            0.4592      0.008     55.611      0.000       0.443       0.475\n",
      "x15            0.0560      0.005     11.808      0.000       0.047       0.065\n",
      "x16           -0.2034      0.005    -39.401      0.000      -0.214      -0.193\n",
      "x17           -0.1780      0.009    -20.805      0.000      -0.195      -0.161\n",
      "x18           -0.0104      0.003     -3.528      0.000      -0.016      -0.005\n",
      "x19           -0.0188      0.004     -5.341      0.000      -0.026      -0.012\n",
      "x20           -0.0663      0.003    -19.280      0.000      -0.073      -0.060\n",
      "x21            0.0207      0.004      5.298      0.000       0.013       0.028\n",
      "==============================================================================\n",
      "                          Results: Logit\n",
      "===================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.208       \n",
      "Dependent Variable: y                AIC:              1459466.8500\n",
      "Date:               2022-09-19 12:59 BIC:              1459742.2752\n",
      "No. Observations:   2021448          Log-Likelihood:   -7.2971e+05 \n",
      "Df Model:           21               LL-Null:          -9.2178e+05 \n",
      "Df Residuals:       2021426          LLR p-value:      0.0000      \n",
      "Converged:          1.0000           Scale:            1.0000      \n",
      "No. Iterations:     7.0000                                         \n",
      "---------------------------------------------------------------------\n",
      "           Coef.    Std.Err.       z       P>|z|     [0.025    0.975]\n",
      "---------------------------------------------------------------------\n",
      "const     -2.0094     0.0026   -777.5986   0.0000   -2.0144   -2.0043\n",
      "x1         0.0330     0.0125      2.6444   0.0082    0.0086    0.0575\n",
      "x2        -0.0347     0.0025    -13.7859   0.0000   -0.0396   -0.0298\n",
      "x3         0.1488     0.0056     26.3557   0.0000    0.1377    0.1599\n",
      "x4         0.3449     0.0057     60.6604   0.0000    0.3338    0.3560\n",
      "x5        -0.0080     0.0032     -2.4934   0.0127   -0.0143   -0.0017\n",
      "x6         0.4324     0.0037    116.9854   0.0000    0.4251    0.4396\n",
      "x7        -0.1339     0.0041    -32.9983   0.0000   -0.1418   -0.1259\n",
      "x8        -0.1488     0.0035    -42.0461   0.0000   -0.1558   -0.1419\n",
      "x9         0.2596     0.0027     96.4974   0.0000    0.2543    0.2649\n",
      "x10        0.7876     0.0023    339.3207   0.0000    0.7831    0.7922\n",
      "x11        0.1297     0.0028     46.6181   0.0000    0.1243    0.1352\n",
      "x12       -0.0638     0.0123     -5.1977   0.0000   -0.0879   -0.0397\n",
      "x13        0.0059     0.0036      1.6222   0.1048   -0.0012    0.0129\n",
      "x14        0.4592     0.0083     55.6113   0.0000    0.4430    0.4754\n",
      "x15        0.0560     0.0047     11.8083   0.0000    0.0467    0.0653\n",
      "x16       -0.2034     0.0052    -39.4010   0.0000   -0.2136   -0.1933\n",
      "x17       -0.1780     0.0086    -20.8050   0.0000   -0.1948   -0.1612\n",
      "x18       -0.0104     0.0030     -3.5275   0.0004   -0.0162   -0.0046\n",
      "x19       -0.0188     0.0035     -5.3413   0.0000   -0.0258   -0.0119\n",
      "x20       -0.0663     0.0034    -19.2799   0.0000   -0.0731   -0.0596\n",
      "x21        0.0207     0.0039      5.2980   0.0000    0.0130    0.0283\n",
      "===================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can use the statsmodel library for logit regression to better understand out model. especially to see if any variables are statistically insignificant. \n",
    "# The 5th variable (site category) seems to be statistically insignificant (P > 0.05). We can take that variable out and rerun the process \n",
    "logit_model=sm.Logit(y_train,sm.add_constant(X_train_tr))\n",
    "logit_model\n",
    "result=logit_model.fit()\n",
    "stats1=result.summary()\n",
    "stats2=result.summary2()\n",
    "print(stats1)\n",
    "print(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.2</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4</td>\n",
       "      <td>banner_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.6</td>\n",
       "      <td>site_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>site_domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>site_category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.6</td>\n",
       "      <td>app_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.9</td>\n",
       "      <td>app_domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.6</td>\n",
       "      <td>app_category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1</td>\n",
       "      <td>device_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.2</td>\n",
       "      <td>device_ip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.8</td>\n",
       "      <td>device_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.6</td>\n",
       "      <td>device_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.5</td>\n",
       "      <td>device_conn_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.4</td>\n",
       "      <td>C14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.4</td>\n",
       "      <td>C15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.5</td>\n",
       "      <td>C16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.6</td>\n",
       "      <td>C17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.2</td>\n",
       "      <td>C18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.7</td>\n",
       "      <td>C19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>C20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.8</td>\n",
       "      <td>C21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor          features\n",
       "0          1.0             const\n",
       "1         12.2                C1\n",
       "2          1.4        banner_pos\n",
       "3          7.6           site_id\n",
       "4          7.4       site_domain\n",
       "5          2.0     site_category\n",
       "6          2.6            app_id\n",
       "7          2.9        app_domain\n",
       "8          2.6      app_category\n",
       "9          1.1         device_id\n",
       "10         1.2         device_ip\n",
       "11         1.8      device_model\n",
       "12        12.6       device_type\n",
       "13         1.5  device_conn_type\n",
       "14        16.4               C14\n",
       "15         4.4               C15\n",
       "16         5.5               C16\n",
       "17        18.6               C17\n",
       "18         2.2               C18\n",
       "19         2.7               C19\n",
       "20         2.0               C20\n",
       "21         3.8               C21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Multicollinearity. This will help us find correlated groups of variables. A high VIF (>10) signifies issues with collinearity. \n",
    "# A few variables show a high VIF meaning we need to go back and do a proper feature selection process.\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "x_temp = sm.add_constant(X_train_tr)\n",
    "\n",
    "hold = ['const']\n",
    "for i in list(X_train)[1:]:\n",
    "    hold.append(i)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(x_temp, i) for i in range(x_temp.shape[1])]\n",
    "vif[\"features\"] = hold\n",
    "vif.round(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7294027a3409cc4d62cb6417bd7be7ac93e88e1112d043191f1fd76f4d16b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
